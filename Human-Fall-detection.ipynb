{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1722 images belonging to 2 classes.\n",
      "Found 430 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.7517 - loss: 0.5432 - val_accuracy: 0.9465 - val_loss: 0.1884 - learning_rate: 1.0000e-04\n",
      "Epoch 2/10\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 938ms/step - accuracy: 0.9446 - loss: 0.1703 - val_accuracy: 0.9605 - val_loss: 0.1495 - learning_rate: 1.0000e-04\n",
      "Epoch 3/10\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 914ms/step - accuracy: 0.9436 - loss: 0.1461 - val_accuracy: 0.9628 - val_loss: 0.1580 - learning_rate: 1.0000e-04\n",
      "Epoch 4/10\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 1s/step - accuracy: 0.9585 - loss: 0.1372 - val_accuracy: 0.9651 - val_loss: 0.1243 - learning_rate: 1.0000e-04\n",
      "Epoch 5/10\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - accuracy: 0.9466 - loss: 0.1444 - val_accuracy: 0.9674 - val_loss: 0.1226 - learning_rate: 1.0000e-04\n",
      "Epoch 6/10\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 1s/step - accuracy: 0.9649 - loss: 0.0952 - val_accuracy: 0.9558 - val_loss: 0.1697 - learning_rate: 1.0000e-04\n",
      "Epoch 7/10\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 932ms/step - accuracy: 0.9621 - loss: 0.1219 - val_accuracy: 0.9674 - val_loss: 0.0841 - learning_rate: 1.0000e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 907ms/step - accuracy: 0.9711 - loss: 0.0831 - val_accuracy: 0.9628 - val_loss: 0.1273 - learning_rate: 1.0000e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 861ms/step - accuracy: 0.9749 - loss: 0.0886 - val_accuracy: 0.9558 - val_loss: 0.1126 - learning_rate: 1.0000e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 900ms/step - accuracy: 0.9683 - loss: 0.0889 - val_accuracy: 0.9674 - val_loss: 0.1148 - learning_rate: 1.0000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model berhasil disimpan di resnet50_fall_detection_optimized.h5\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 617ms/step - accuracy: 0.9708 - loss: 0.0949\n",
      "Akurasi Validasi: 96.98%\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 667ms/step\n",
      "Prediksi berhasil disimpan ke test_predictions_optimized.csv\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Lokasi dataset\n",
    "train_dir = r\"D:\\Data Slayer Olah\\DataSlayer\"\n",
    "test_dir = r\"D:\\Data Slayer Olah\\data\\test\"\n",
    "\n",
    "# Augmentasi Data untuk Latihan\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.resnet50.preprocess_input,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Dataset Training dan Validation\n",
    "train_dataset = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='training',\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "val_dataset = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='validation',\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "# Bangun Model ResNet50\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "\n",
    "# Bekukan sebagian besar layer, kecuali beberapa layer terakhir\n",
    "for layer in base_model.layers[:-10]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Tambahkan lapisan tambahan di atas model dasar\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Kompilasi Model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
    "]\n",
    "\n",
    "# Latih Model\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=10,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# Simpan Model\n",
    "model_path = 'resnet50_fall_detection_optimized.h5'\n",
    "model.save(model_path)\n",
    "print(f\"Model berhasil disimpan di {model_path}\")\n",
    "\n",
    "# Evaluasi Model\n",
    "loss, accuracy = model.evaluate(val_dataset)\n",
    "print(f\"Akurasi Validasi: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Prediksi pada Dataset Uji\n",
    "def load_and_preprocess_images(test_dir, target_size):\n",
    "    test_images = []\n",
    "    image_names = []\n",
    "\n",
    "    for img_name in os.listdir(test_dir):\n",
    "        img_path = os.path.join(test_dir, img_name)\n",
    "        try:\n",
    "            img = image.load_img(img_path, target_size=target_size)\n",
    "            img_array = image.img_to_array(img)\n",
    "            img_array = tf.keras.applications.resnet50.preprocess_input(img_array)\n",
    "            test_images.append(img_array)\n",
    "            image_names.append(img_name)\n",
    "        except Exception as e:\n",
    "            print(f\"Gagal memproses {img_name}: {e}\")\n",
    "\n",
    "    return np.array(test_images), image_names\n",
    "\n",
    "# Load and preprocess test images\n",
    "test_images, image_names = load_and_preprocess_images(test_dir, target_size=(150, 150))\n",
    "\n",
    "# Prediksi\n",
    "def generate_predictions(model, test_images, image_names, output_csv):\n",
    "    predictions = model.predict(test_images)\n",
    "    df = pd.DataFrame({\n",
    "        'id': image_names,\n",
    "        'label': predictions.flatten()\n",
    "    })\n",
    "    # Inversi label (1 = Fall, 0 = Non-Fall)\n",
    "    df['label'] = df['label'].apply(lambda x: 0 if x > 0.5 else 1)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Prediksi berhasil disimpan ke {output_csv}\")\n",
    "\n",
    "output_csv = 'test_predictions_optimized.csv'\n",
    "generate_predictions(model, test_images, image_names, output_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1722 images belonging to 2 classes.\n",
      "Found 430 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 910ms/step - accuracy: 0.6864 - loss: 0.5737 - val_accuracy: 0.9163 - val_loss: 0.2719 - learning_rate: 1.0000e-04\n",
      "Epoch 2/10\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 849ms/step - accuracy: 0.8922 - loss: 0.2823 - val_accuracy: 0.9140 - val_loss: 0.2151 - learning_rate: 1.0000e-04\n",
      "Epoch 3/10\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 1s/step - accuracy: 0.9281 - loss: 0.2237 - val_accuracy: 0.9465 - val_loss: 0.1741 - learning_rate: 1.0000e-04\n",
      "Epoch 4/10\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 1s/step - accuracy: 0.9342 - loss: 0.2041 - val_accuracy: 0.9442 - val_loss: 0.1637 - learning_rate: 1.0000e-04\n",
      "Epoch 5/10\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 838ms/step - accuracy: 0.9337 - loss: 0.1949 - val_accuracy: 0.9465 - val_loss: 0.1404 - learning_rate: 1.0000e-04\n",
      "Epoch 6/10\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 840ms/step - accuracy: 0.9269 - loss: 0.1894 - val_accuracy: 0.9651 - val_loss: 0.1214 - learning_rate: 1.0000e-04\n",
      "Epoch 7/10\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 815ms/step - accuracy: 0.9548 - loss: 0.1584 - val_accuracy: 0.9488 - val_loss: 0.1255 - learning_rate: 1.0000e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 815ms/step - accuracy: 0.9463 - loss: 0.1562 - val_accuracy: 0.9605 - val_loss: 0.1142 - learning_rate: 1.0000e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 844ms/step - accuracy: 0.9573 - loss: 0.1230 - val_accuracy: 0.9535 - val_loss: 0.1232 - learning_rate: 1.0000e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 812ms/step - accuracy: 0.9521 - loss: 0.1603 - val_accuracy: 0.9605 - val_loss: 0.0976 - learning_rate: 1.0000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model berhasil disimpan di efficientnetv2s_fall_detection_optimized.h5\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 746ms/step - accuracy: 0.9643 - loss: 0.0961\n",
      "Akurasi Validasi: 95.81%\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 774ms/step\n",
      "Prediksi berhasil disimpan ke test_predictions_efficienetv2s.csv\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetV2S\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Lokasi dataset\n",
    "train_dir = r\"D:\\Data Slayer Olah\\DataSlayer\"\n",
    "test_dir = r\"D:\\Data Slayer Olah\\data\\test\"\n",
    "\n",
    "# Augmentasi Data untuk Latihan\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.efficientnet_v2.preprocess_input,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Dataset Training dan Validation\n",
    "train_dataset = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='training',\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "val_dataset = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='validation',\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "# Bangun Model EfficientNetV2S\n",
    "base_model = EfficientNetV2S(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "\n",
    "# Bekukan sebagian besar layer, kecuali beberapa layer terakhir\n",
    "for layer in base_model.layers[:-10]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Tambahkan lapisan tambahan di atas model dasar\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Kompilasi Model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
    "]\n",
    "\n",
    "# Latih Model\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=10,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# Simpan Model\n",
    "model_path = 'efficientnetv2s_fall_detection_optimized.h5'\n",
    "model.save(model_path)\n",
    "print(f\"Model berhasil disimpan di {model_path}\")\n",
    "\n",
    "# Evaluasi Model\n",
    "loss, accuracy = model.evaluate(val_dataset)\n",
    "print(f\"Akurasi Validasi: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Prediksi pada Dataset Uji\n",
    "def load_and_preprocess_images(test_dir, target_size):\n",
    "    test_images = []\n",
    "    image_names = []\n",
    "\n",
    "    for img_name in os.listdir(test_dir):\n",
    "        img_path = os.path.join(test_dir, img_name)\n",
    "        try:\n",
    "            img = image.load_img(img_path, target_size=target_size)\n",
    "            img_array = image.img_to_array(img)\n",
    "            img_array = tf.keras.applications.efficientnet_v2.preprocess_input(img_array)\n",
    "            test_images.append(img_array)\n",
    "            image_names.append(img_name)\n",
    "        except Exception as e:\n",
    "            print(f\"Gagal memproses {img_name}: {e}\")\n",
    "\n",
    "    return np.array(test_images), image_names\n",
    "\n",
    "# Load and preprocess test images\n",
    "test_images, image_names = load_and_preprocess_images(test_dir, target_size=(150, 150))\n",
    "\n",
    "# Prediksi\n",
    "def generate_predictions(model, test_images, image_names, output_csv):\n",
    "    predictions = model.predict(test_images)\n",
    "    df = pd.DataFrame({\n",
    "        'id': image_names,\n",
    "        'label': predictions.flatten()\n",
    "    })\n",
    "    # Inversi label (1 = Fall, 0 = Non-Fall)\n",
    "    df['label'] = df['label'].apply(lambda x: 0 if x > 0.5 else 1)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Prediksi berhasil disimpan ke {output_csv}\")\n",
    "\n",
    "output_csv = 'test_predictions_efficienetv2s.csv'\n",
    "generate_predictions(model, test_images, image_names, output_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the two CSV files\n",
    "file1_path = 'path_to_file1.csv'  # Ganti dengan path file pertama\n",
    "file2_path = 'path_to_file2.csv'  # Ganti dengan path file kedua\n",
    "\n",
    "# Read the files into DataFrames\n",
    "df1 = pd.read_csv(file1_path)\n",
    "df2 = pd.read_csv(file2_path)\n",
    "\n",
    "# Merge the two DataFrames on a common column (e.g., 'id')\n",
    "comparison = pd.merge(df1, df2, on='id', how='outer', suffixes=('_file1', '_file2'))\n",
    "\n",
    "# Find rows where there are differences in the 'label' column\n",
    "differences = comparison[comparison['label_file1'] != comparison['label_file2']]\n",
    "\n",
    "# Save differences to a new CSV file\n",
    "output_path = 'differences.csv'\n",
    "differences.to_csv(output_path, index=False)\n",
    "print(f\"Differences saved to {output_path}\")\n",
    "\n",
    "# Print summary of differences\n",
    "print(f\"Total differences: {len(differences)}\")\n",
    "print(differences)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
